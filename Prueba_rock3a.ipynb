{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJS3B0m2r8lJDF7JgrkW7t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pjrios/Rock3a/blob/main/Prueba_rock3a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install paho-mqtt openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HysBVjgiOV6H",
        "outputId": "79947fe3-a09a-413d-b887-87341f587401"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: paho-mqtt in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnTG2ydcOUkm",
        "outputId": "52e40b2d-28ea-4a61-dfb5-182956a8c29a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client: <paho.mqtt.client.Client object at 0x7bd11a098790>userdata: Nonemid: 2\n",
            "CONNACK received with code Success.\n",
            "client: <paho.mqtt.client.Client object at 0x7bd11a098790>userdata: Nonemid: 3\n",
            "client: <paho.mqtt.client.Client object at 0x7bd11a098790>userdata: Nonemid: 4\n",
            "client: <paho.mqtt.client.Client object at 0x7bd11a098790>userdata: Nonemid: 5\n",
            "client: <paho.mqtt.client.Client object at 0x7bd11a098790>userdata: Nonemid: 6\n",
            "client: <paho.mqtt.client.Client object at 0x7bd11a098790>userdata: Nonemid: 7\n",
            "client: <paho.mqtt.client.Client object at 0x7bd11a098790>userdata: Nonemid: 8\n",
            "client: <paho.mqtt.client.Client object at 0x7bd11a098790>userdata: Nonemid: 9\n",
            "client: <paho.mqtt.client.Client object at 0x7bd11a098790>userdata: Nonemid: 10\n",
            "here!!\n",
            "Explanation: \n",
            "\n",
            "The data shows a gradual increase in temperature and decrease in humidity over time.\n",
            "client: <paho.mqtt.client.Client object at 0x7bd11a098790>userdata: Nonemid: 11\n",
            "Monitoring stopped by the user.\n"
          ]
        }
      ],
      "source": [
        "import paho.mqtt.client as mqtt\n",
        "import openai\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "# Configuración de Callbacks MQTT\n",
        "def on_connect(client, userdata, flags, rc, properties=None):\n",
        "    print(\"CONNACK received with code %s.\" % rc)\n",
        "\n",
        "def on_publish(client, userdata, mid, properties=None):\n",
        "    print(\"client: \" + str(client) + \"userdata: \" + str(userdata) + \"mid: \" + str(mid))\n",
        "\n",
        "def on_subscribe(client, userdata, mid, granted_qos, properties=None):\n",
        "    print(\"Subscribed: \" + str(mid) + \" \" + str(granted_qos))\n",
        "\n",
        "def on_message(client, userdata, msg):\n",
        "    print(msg.topic + \" \" + str(msg.qos) + \" \" + str(msg.payload))\n",
        "\n",
        "# Configuración de variables MQTT\n",
        "USER = \"pjriosc\"\n",
        "PASSWORD = \"arduino-conections-101\"\n",
        "ADDR = \"4f2f4dcf13da4bd89f97a93716d25684.s2.eu.hivemq.cloud\"\n",
        "\n",
        "# Inicializamos el cliente MQTT\n",
        "client = mqtt.Client(client_id=\"\", userdata=None, protocol=mqtt.MQTTv5)\n",
        "client.on_connect = on_connect\n",
        "\n",
        "client.tls_set(tls_version=mqtt.ssl.PROTOCOL_TLS)\n",
        "client.username_pw_set(USER, PASSWORD)\n",
        "client.connect(ADDR, 8883)\n",
        "\n",
        "client.on_subscribe = on_subscribe\n",
        "client.on_message = on_message\n",
        "client.on_publish = on_publish\n",
        "\n",
        "client.subscribe(\"Arduino/MQTT\", qos=1)\n",
        "client.loop_start()\n",
        "\n",
        "# Configuration (you can load these from environment variables or a config file)\n",
        "mqtt_broker_address = \"mqtt.example.com\"\n",
        "mqtt_port = 1883\n",
        "mqtt_topic = \"sensor/data\"\n",
        "openai_api_key = \"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\"\n",
        "temperature_threshold = 2.0  # Adjustable threshold for temperature change\n",
        "\n",
        "# Initialize previous values for change detection\n",
        "previous_temperature = 25.0\n",
        "previous_humidity = 50.0\n",
        "\n",
        "# Initialize simulated sensor data\n",
        "simulated_temperature = 25.0\n",
        "simulated_humidity = 50.0\n",
        "\n",
        "# Set up your OpenAI API key\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "# Initialize a list to store sensor readings with (temperature, humidity, timestamp)\n",
        "sensor_readings = []\n",
        "\n",
        "# Define a function to read sensor data and append it to the list\n",
        "def publish_sensor_data():\n",
        "    global previous_temperature, previous_humidity, simulated_temperature, simulated_humidity, sensor_readings\n",
        "\n",
        "    # Simulate sensor data here\n",
        "    simulated_temperature += 1  # Increase temperature every 1 second\n",
        "    simulated_humidity -= 1  # Decrease humidity every 2 seconds\n",
        "    if simulated_humidity < 0.0:\n",
        "        simulated_humidity = 0.0\n",
        "\n",
        "    # Get the current timestamp\n",
        "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    # Append the simulated data to the list with timestamp\n",
        "    sensor_readings.append((simulated_temperature, simulated_humidity, current_time))\n",
        "\n",
        "    # Publish simulated data to MQTT\n",
        "    client.publish(mqtt_topic, f\"Temperature: {simulated_temperature:.2f}°C, Humidity: {simulated_humidity:.2f}%\")\n",
        "\n",
        "    # Check for significant changes and request an explanation\n",
        "    check_for_changes(simulated_temperature, simulated_humidity)\n",
        "\n",
        "# Define a function to check for significant changes and request an explanation from ChatGPT\n",
        "def check_for_changes(new_temperature, new_humidity):\n",
        "    global previous_temperature, previous_humidity\n",
        "\n",
        "    # Example: If temperature increased by more than the threshold\n",
        "    if abs(new_temperature - previous_temperature) > temperature_threshold:\n",
        "        explanation = chat_with_gpt(f\"My system detected a significant temperature change. \"\n",
        "                                    f\"Current temperature: {new_temperature:.2f}°C, \"\n",
        "                                    f\"Previous temperature: {previous_temperature:.2f}°C, \"\n",
        "                                    f\"Current humidity: {new_humidity:.2f}%, \"\n",
        "                                    f\"Previous humidity: {previous_humidity:.2f}%. \"\n",
        "                                    f\"Why did the temperature change significantly?\")\n",
        "        print(\"Explanation:\", explanation)\n",
        "\n",
        "    # Update the previous values for the next check\n",
        "    previous_temperature = new_temperature\n",
        "    previous_humidity = new_humidity\n",
        "\n",
        "# Define a function to interact with ChatGPT\n",
        "def chat_with_gpt(prompt):\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-002\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=50  # Adjust as needed\n",
        "    )\n",
        "    return response.choices[0].text\n",
        "\n",
        "# Connect to the MQTT broker and start the monitoring loop\n",
        "client.connect(\"4f2f4dcf13da4bd89f97a93716d25684.s2.eu.hivemq.cloud\", 8883)\n",
        "client.loop_start()\n",
        "seconds = 0\n",
        "\n",
        "# Main loop for publishing sensor data\n",
        "try:\n",
        "    while True:\n",
        "        # Collect sensor data and send it to ChatGPT every 1 minute\n",
        "        seconds += 1\n",
        "        if seconds == 10:\n",
        "            print(\"here!!\")\n",
        "            latest_reading = sensor_readings[-1]  # Get the latest reading from the list\n",
        "            current_temperature, current_humidity, current_time = latest_reading\n",
        "            explanation = chat_with_gpt(f\"I have a set of data over time in the form of (temperature in °C, humidity, time): {sensor_readings}, \"\n",
        "                                        f\"What can you infer from this data?\")\n",
        "            print(\"Explanation:\", explanation)\n",
        "            seconds = 0\n",
        "\n",
        "        # Publish sensor data every 1 second\n",
        "        publish_sensor_data()\n",
        "        time.sleep(10)  # Wait for 1 second\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Monitoring stopped by the user.\")\n",
        "    client.disconnect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sensor_readings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnhdOlGAdimY",
        "outputId": "74805a66-ba1d-441c-e984-ea627e66f77a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(26.0, 49.0, '2023-09-03 23:30:56'), (27.0, 48.0, '2023-09-03 23:30:57'), (28.0, 47.0, '2023-09-03 23:30:58'), (29.0, 46.0, '2023-09-03 23:30:59'), (30.0, 45.0, '2023-09-03 23:31:00'), (31.0, 44.0, '2023-09-03 23:31:01'), (32.0, 43.0, '2023-09-03 23:31:02'), (33.0, 42.0, '2023-09-03 23:31:03'), (34.0, 41.0, '2023-09-03 23:31:04'), (35.0, 40.0, '2023-09-03 23:31:06'), (36.0, 39.0, '2023-09-03 23:31:07'), (37.0, 38.0, '2023-09-03 23:31:08'), (38.0, 37.0, '2023-09-03 23:31:09')]\n"
          ]
        }
      ]
    }
  ]
}